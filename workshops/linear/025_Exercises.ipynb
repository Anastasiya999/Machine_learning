{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "There are three exercises in this notebook:\n",
    "\n",
    "1. Use the cross-validation method to test the linear regression with different $\\alpha$ values, at least three.\n",
    "2. Implement a SGD method that will train the Lasso regression for 10 epochs.\n",
    "3. Extend the Fisher's classifier to work with two features. Use the class as the $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross-validation linear regression\n",
    "\n",
    "You need to change the variable ``alpha`` to be a list of alphas. Next do a loop and finally compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.   -0.98 -0.96 -0.94 -0.92 -0.9  -0.88 -0.86 -0.84 -0.82 -0.8  -0.78\n",
      " -0.76 -0.74 -0.72 -0.7  -0.68 -0.66 -0.64 -0.62 -0.6  -0.58 -0.56 -0.54\n",
      " -0.52 -0.5  -0.48 -0.46 -0.44 -0.42 -0.4  -0.38 -0.36 -0.34 -0.32 -0.3\n",
      " -0.28 -0.26 -0.24 -0.22 -0.2  -0.18 -0.16 -0.14 -0.12 -0.1  -0.08 -0.06\n",
      " -0.04 -0.02  0.    0.02  0.04  0.06  0.08  0.1   0.12  0.14  0.16  0.18\n",
      "  0.2   0.22  0.24  0.26  0.28  0.3   0.32  0.34  0.36  0.38  0.4   0.42\n",
      "  0.44  0.46  0.48  0.5   0.52  0.54  0.56  0.58  0.6   0.62  0.64  0.66\n",
      "  0.68  0.7   0.72  0.74  0.76  0.78  0.8   0.82  0.84  0.86  0.88  0.9\n",
      "  0.92  0.94  0.96  0.98]\n",
      "741.3534123255498 0\n",
      "743.5832113680598 1\n",
      "745.9274783061886 2\n",
      "748.3952220797562 3\n",
      "750.9964187192851 4\n",
      "753.7421442130618 5\n",
      "756.6447298222574 6\n",
      "759.71794438253 7\n",
      "762.9772092071312 8\n",
      "766.4398525782417 9\n",
      "770.125412572954 10\n",
      "774.0559992427801 11\n",
      "778.2567301228265 12\n",
      "782.7562569245251 13\n",
      "787.5874063930411 14\n",
      "792.7879651499354 15\n",
      "798.4016475501817 16\n",
      "804.4792981056459 17\n",
      "811.0803972400865 18\n",
      "818.2749630714275 19\n",
      "826.1459755987879 20\n",
      "834.7924977076397 21\n",
      "844.333736899309 22\n",
      "854.9143937521314 23\n",
      "866.711795675516 24\n",
      "879.945546677745 25\n",
      "894.8907843480746 26\n",
      "911.8967075052024 27\n",
      "931.4129689087646 28\n",
      "954.0280837044634 29\n",
      "980.5266864294132 30\n",
      "1011.977253519544 31\n",
      "1049.8707813243886 32\n",
      "1096.3481201125835 33\n",
      "1154.5888258655314 34\n",
      "1229.5107461161267 35\n",
      "1329.10788902684 36\n",
      "1467.2092503473573 37\n",
      "1669.7387568911956 38\n",
      "1990.8238651672864 39\n",
      "2562.137053755637 40\n",
      "3789.1509908508833 41\n",
      "7578.534298026378 42\n",
      "41510.86915482485 43\n",
      "56990.817992124 44\n",
      "3837.1187406047698 45\n",
      "1136.786328029722 46\n",
      "587.7489082572229 47\n",
      "429.6678148786005 48\n",
      "381.8657542434754 49\n",
      "372.3312921517967 50\n",
      "377.4196885131721 51\n",
      "388.13848677115465 52\n",
      "400.74863864480966 53\n",
      "413.62145706941504 54\n",
      "426.0450770831748 55\n",
      "437.7272024060601 56\n",
      "448.5731846149154 57\n",
      "458.5818354317617 58\n",
      "467.7947492065921 59\n",
      "476.2711324869076 60\n",
      "484.07524438229206 61\n",
      "491.2702392154449 62\n",
      "497.91531373121563 63\n",
      "504.06456902340744 64\n",
      "509.7667538092898 65\n",
      "515.0654461000682 66\n",
      "519.9994364758276 67\n",
      "524.6031869686798 68\n",
      "528.9072998277749 69\n",
      "532.9389634225964 70\n",
      "536.7223605616125 71\n",
      "540.2790342304714 72\n",
      "543.6282108558403 73\n",
      "546.787083722665 74\n",
      "549.7710602647363 75\n",
      "552.59397726389 76\n",
      "555.2682879012899 77\n",
      "557.8052243146735 78\n",
      "560.2149389444754 79\n",
      "562.5066275634506 80\n",
      "564.6886365115097 81\n",
      "566.7685563158195 82\n",
      "568.7533035718455 83\n",
      "570.6491926943183 84\n",
      "572.461998916274 85\n",
      "574.1970137158878 86\n",
      "575.8590936810615 87\n",
      "577.4527036769169 88\n",
      "578.9819550581033 89\n",
      "580.4506395628902 90\n",
      "581.8622594367808 91\n",
      "583.220054257388 92\n",
      "584.5270248675661 93\n",
      "585.7859547686433 94\n",
      "586.99942927835 95\n",
      "588.1698527177757 96\n",
      "589.2994638570993 97\n",
      "590.3903498201682 98\n",
      "591.4444586225426 99\n",
      "optimal alpha is  0.98 372.3312921517967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "def reg_predict(inputs, w, b):\n",
    "    results = []\n",
    "    for inp in inputs:\n",
    "        results.append(inp*w+b)\n",
    "    return results\n",
    "\n",
    "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\n",
    "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n",
    "temp = x\n",
    "x = np.asmatrix(np.c_[np.ones((15,1)),x])\n",
    "\n",
    "I = np.identity(2)\n",
    "alpha = 0.1 # change here\n",
    "alphas = np.linspace(-1, 1, 100, endpoint=False)\n",
    "coeffs = []\n",
    "\n",
    "# add 1-3 line of code here\n",
    "for alpha in alphas:\n",
    "    w = np.linalg.inv(x.T*x + alpha * I)*x.T*y\n",
    "    w=w.ravel()\n",
    "    w=w.tolist()[0]\n",
    "    coeffs.append(w)\n",
    "    \n",
    "from sklearn.metrics import mean_squared_error\n",
    "# add 1-3 lines to compare the results\n",
    "min_val = 1000000\n",
    "min_index = 0\n",
    "\n",
    "for i, coeff in enumerate(coeffs):\n",
    "    error = mean_squared_error(y, reg_predict(temp.flatten(), coeff[1], coeff[0]) )\n",
    "    if min_val > abs(error):\n",
    "        min_val = abs(error)\n",
    "        min_index = i\n",
    "print(\"optimal alpha is \", alphas[i], min_val)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement based on the Ridge regression example, the Lasso regression.\n",
    "\n",
    "Please implement the SGD method and compare the results with the sklearn Lasso regression results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd():\n",
    "    # your code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\n",
    "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n",
    "\n",
    "x = np.asmatrix(np.c_[np.ones((15,1)),x])\n",
    "\n",
    "I = np.identity(2)\n",
    "alpha = 0.1 \n",
    "\n",
    "\n",
    "w = np.linalg.inv(x.T*x + alpha * I)*x.T*y # update this line\n",
    "w=w.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extend the Fisher's classifier\n",
    "\n",
    "Please extend the targets of the ``iris_data`` variable and use it as the $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "iris_df = pd.DataFrame(iris_data.data,columns=iris_data.feature_names)\n",
    "iris_df.head()\n",
    "\n",
    "x = iris_df['sepal width (cm)'].values # change here\n",
    "y = iris_df['sepal length (cm)'].values # change here\n",
    "\n",
    "dataset_size = np.size(x)\n",
    "\n",
    "mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "\n",
    "SS_xy = np.sum(y * x) - dataset_size * mean_y * mean_x\n",
    "SS_xx = np.sum(x * x) - dataset_size * mean_x * mean_x\n",
    "\n",
    "a = SS_xy / SS_xx\n",
    "b = mean_y - a * mean_x\n",
    "\n",
    "\n",
    "y_pred = a * x + b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
