{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "There are three exercises in this notebook:\n",
    "\n",
    "1. Use the cross-validation method to test the linear regression with different $\\alpha$ values, at least three.\n",
    "2. Implement a SGD method that will train the Lasso regression for 10 epochs.\n",
    "3. Extend the Fisher's classifier to work with two features. Use the class as the $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross-validation linear regression\n",
    "\n",
    "You need to change the variable ``alpha`` to be a list of alphas. Next do a loop and finally compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal alpha is  0.98 372.3312921517967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "def reg_predict(inputs, w, b):\n",
    "    results = []\n",
    "    for inp in inputs:\n",
    "        results.append(inp*w+b)\n",
    "    return results\n",
    "\n",
    "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\n",
    "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n",
    "temp = x\n",
    "x = np.asmatrix(np.c_[np.ones((15,1)),x])\n",
    "\n",
    "I = np.identity(2)\n",
    "alpha = 0.1 # change here\n",
    "alphas = np.linspace(-1, 1, 100, endpoint=False)\n",
    "coeffs = []\n",
    "\n",
    "# add 1-3 line of code here\n",
    "for alpha in alphas:\n",
    "    w = np.linalg.inv(x.T*x + alpha * I)*x.T*y\n",
    "    w=w.ravel()\n",
    "    w=w.tolist()[0]\n",
    "    coeffs.append(w)\n",
    "    \n",
    "from sklearn.metrics import mean_squared_error\n",
    "# add 1-3 lines to compare the results\n",
    "min_val = 1000000\n",
    "min_index = 0\n",
    "\n",
    "for i, coeff in enumerate(coeffs):\n",
    "    error = mean_squared_error(y, reg_predict(temp.flatten(), coeff[1], coeff[0]) )\n",
    "    if min_val > abs(error):\n",
    "        min_val = abs(error)\n",
    "        min_index = i\n",
    "print(\"optimal alpha is \", alphas[i], min_val)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement based on the Ridge regression example, the Lasso regression.\n",
    "\n",
    "Please implement the SGD method and compare the results with the sklearn Lasso regression results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([1., 1.]),\n",
       "  array([   -8.6, -1803.8]),\n",
       "  array([   65311.88, 11821203.08]),\n",
       "  array([-4.65703122e+08, -9.17445603e+10]),\n",
       "  array([3.08224466e+12, 5.17803597e+14]),\n",
       "  array([-1.72921743e+16, -2.88779005e+18]),\n",
       "  array([1.07989514e+20, 2.01943850e+22]),\n",
       "  array([-7.18833713e+23, -1.27951429e+26]),\n",
       "  array([4.96394037e+27, 9.63015933e+29]),\n",
       "  array([-2.69604750e+31, -3.77419843e+33]),\n",
       "  array([1.32830216e+35, 2.33790889e+37]),\n",
       "  array([-7.85431124e+38, -1.31951365e+41]),\n",
       "  array([5.06630408e+42, 9.72749235e+44]),\n",
       "  array([-3.36530705e+46, -5.82188492e+48]),\n",
       "  array([1.65314609e+50, 2.34736314e+52])],\n",
       " [2304.0,\n",
       "  106669127685.76001,\n",
       "  5.423505851093544e+18,\n",
       "  2.375775800267225e+26,\n",
       "  7.478147509999271e+33,\n",
       "  2.916367544738654e+41,\n",
       "  1.2921929293769652e+49,\n",
       "  6.16196024181244e+56,\n",
       "  1.817837240342625e+64,\n",
       "  4.4127573655108617e+71,\n",
       "  1.5427768164236674e+79,\n",
       "  6.418849031452637e+86,\n",
       "  2.832175430736744e+94,\n",
       "  6.835011954895591e+101,\n",
       "  1.70694941346678e+109],\n",
       " [array([   96., 18048.]),\n",
       "  array([-6.53204800e+05, -1.18230069e+08]),\n",
       "  array([4.65768434e+09, 9.17563815e+11]),\n",
       "  array([-3.08271037e+13, -5.17895341e+15]),\n",
       "  array([1.72952566e+17, 2.88830785e+19]),\n",
       "  array([-1.08006806e+21, -2.01972728e+23]),\n",
       "  array([7.18941703e+24, 1.27971623e+27]),\n",
       "  array([-4.96465920e+28, -9.63143885e+30]),\n",
       "  array([2.69654389e+32, 3.77516145e+34]),\n",
       "  array([-1.32857177e+36, -2.33828631e+38]),\n",
       "  array([7.85563954e+39, 1.31974744e+42]),\n",
       "  array([-5.06708951e+43, -9.72881186e+45]),\n",
       "  array([3.36581368e+47, 5.82285766e+49]),\n",
       "  array([-1.65348262e+51, -2.34794532e+53]),\n",
       "  array([8.26304886e+54, 1.45429660e+57])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def E(w,x, y):\n",
    "    # E(a,b) = (y - (a*x +b))^2 \n",
    "    return (y-(w[1]*x+w[0]))**2\n",
    "\n",
    "\n",
    "# This is the gradient of the Error function used to update the equation's coefficients (a and b) for SGD\n",
    "def gradientE(w,x, y):\n",
    "    \n",
    "    gradientW1 = -2*x*(y-(w[1]*x+w[0]))\n",
    "    gradientW0 = -2*(y-(x*w[1]+w[0]))\n",
    "\n",
    "    return np.array([gradientW0.item(0),gradientW1.item(0)])\n",
    "def stochasticGradientDescent(x_data, y_data, learningRate):\n",
    "    coefHistory = [] # Used to save the value of a and b at each iteration\n",
    "    lossHistory = [] # Used to save the value of the loss at each iteration\n",
    "    gradientHistory = [] # Used to save the value of the gradient at each iteration\n",
    "    w = np.array([1.0, 1.0]) #starting coeficients\n",
    "    nbIteration = 15\n",
    "    for _ in range((int)(nbIteration/len(y_data))):\n",
    "         for i in range(len(y_data)):\n",
    "            loss = E(w,x_data[i, 1], y_data[i].item(0)) # Compute the loss for one data and the coefficients a and b\n",
    "            grad = gradientE(w,x_data[i, 1], y_data[i]) # Compute the gradient for one data\n",
    "\n",
    "            # Save the coefficients, loss and gradient of the current data in the lists\n",
    "            coefHistory.append(w)\n",
    "            lossHistory.append(loss)\n",
    "            gradientHistory.append(grad)\n",
    "\n",
    "            w = w-learningRate*grad # Update the coefficients a and b \n",
    "            \n",
    "    return coefHistory, lossHistory, gradientHistory\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def sgd(x_data, y_data, alpha):\n",
    "    norma = np.linalg.norm(x_data, axis=0)\n",
    "    R1 = 1 / (norma[1] * norma[1])\n",
    "    R0 = 1 / (norma[0] * norma[0])\n",
    "    def apply_penalty(w, x, y_delta):\n",
    "        if w > 0:\n",
    "            dW1 = (-x.T.dot(y_delta) * 2 + alpha) * R1\n",
    "        else:\n",
    "            dW1 = (-x.T.dot(y_delta) * 2 - alpha) * R1\n",
    "        dW0 = (-np.sum(y_delta) * 2) * R0\n",
    "        return (dW1, dW0)\n",
    "    def update_weights(dW1, dW0, w):\n",
    "        w[0] = w[0] - alpha * dW0\n",
    "        w[1] = w[1] - alpha * dW1\n",
    "    \n",
    "    w = np.array([1.0, 1.0])\n",
    " \n",
    "    epochs = 710\n",
    "    for i in range(epochs):\n",
    "        x = x_data[:, 1].reshape(-1, 1)\n",
    "        y_hat = x * w[1] + w[0]\n",
    "        y_delta = y - y_hat\n",
    "        \n",
    "        dW1, dW0 = apply_penalty(w[1], x, y_delta)\n",
    "        update_weights(dW1, dW0, w)\n",
    "        \n",
    "        \n",
    "    return w\n",
    "\n",
    "sgd(x, y, 0.1)\n",
    "#stochasticGradientDescent(x, y, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>w[1]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>-101.925922</td>\n",
       "      <td>1.169004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>-101.723971</td>\n",
       "      <td>1.169788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bias      w[1]\n",
       "sgd   -101.925922  1.169004\n",
       "lasso -101.723971  1.169788"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\n",
    "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n",
    "\n",
    "x = np.asmatrix(np.c_[np.ones((15,1)),x])\n",
    "\n",
    "I = np.identity(2)\n",
    "alpha = 0.1 \n",
    "\n",
    "sgd_coef = sgd(x, y, alpha)\n",
    "sgd_coef = sgd_coef.ravel()\n",
    "\n",
    "w = np.linalg.inv(x.T*x + alpha * I)*x.T*y # update this line\n",
    "w = w.ravel()\n",
    "\n",
    "compare_coef = np.asarray([sgd_coef[0], sgd_coef[1], w.item(0), w.item(1)])\n",
    "compare_coef = compare_coef.flatten()\n",
    "\n",
    "final_result = pd.DataFrame(data=compare_coef.reshape(2, 2), index=['sgd', 'lasso'], columns=[\"bias\", \"w[1]\"])\n",
    "final_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extend the Fisher's classifier\n",
    "\n",
    "Please extend the targets of the ``iris_data`` variable and use it as the $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8132192495093759\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "iris_df = pd.DataFrame(iris_data.data,columns=iris_data.feature_names)\n",
    "iris_df.head()\n",
    "\n",
    "x = iris_df[['sepal width (cm)','sepal length (cm)']].values # change here\n",
    "y = iris_data.target.reshape(-1, 1)# change here\n",
    "\n",
    "dataset_size = np.size(y)\n",
    "\n",
    "mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "\n",
    "SS_xy = np.sum(y * x) - dataset_size * mean_y * mean_x\n",
    "SS_xx = np.sum(x * x) - dataset_size * mean_x * mean_x\n",
    "\n",
    "a = SS_xy / SS_xx\n",
    "b = mean_y - a * mean_x\n",
    "\n",
    "\n",
    "y_pred = a * x + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
